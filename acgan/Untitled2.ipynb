{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batchSize=64, beta1=0.5, cuda=True, dataroot='/home/ubuntu/xray_gan/data/toytestdata/classes', dataset='toytestdata', gpu_id=0, imageSize=32, lr=0.0002, manualSeed=None, ndf=64, netD='', netG='', ngf=64, ngpu=1, niter=2, num_classes=2, nz=110, outf='.', workers=2)\n",
      "Random Seed:  6877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision/transforms/transforms.py:211: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netG_CIFAR10(\n",
      "  (fc1): Linear(in_features=110, out_features=384, bias=True)\n",
      "  (tconv2): Sequential(\n",
      "    (0): ConvTranspose2d(384, 192, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (tconv3): Sequential(\n",
      "    (0): ConvTranspose2d(192, 96, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (tconv4): Sequential(\n",
      "    (0): ConvTranspose2d(96, 48, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (tconv5): Sequential(\n",
      "    (0): ConvTranspose2d(48, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n",
      "_netD_CIFAR10(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (conv6): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc_dis): Linear(in_features=8192, out_features=1, bias=True)\n",
      "  (fc_aux): Linear(in_features=8192, out_features=2, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/xray_gan/acgan/network.py:276: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  classes = self.softmax(fc_aux)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n",
      "[0/2][0/32] Loss_D: 0.4831 (0.4831) Loss_G: 0.2422 (0.2422) D(x): 0.4038 D(G(z)): 0.4058 / 0.4791 Acc: 57.8125 (57.8125)\n",
      "(64,)\n",
      "[0/2][1/32] Loss_D: 0.5204 (0.5017) Loss_G: 0.2443 (0.2432) D(x): 0.4595 D(G(z)): 0.4785 / 0.4951 Acc: 53.1250 (55.4688)\n",
      "(64,)\n",
      "[0/2][2/32] Loss_D: 0.4173 (0.4736) Loss_G: 0.3213 (0.2693) D(x): 0.5535 D(G(z)): 0.5265 / 0.4740 Acc: 45.3125 (52.0833)\n",
      "(64,)\n",
      "[0/2][3/32] Loss_D: 0.3323 (0.4383) Loss_G: 0.3339 (0.2854) D(x): 0.5614 D(G(z)): 0.4862 / 0.4405 Acc: 43.7500 (50.0000)\n",
      "(64,)\n",
      "[0/2][4/32] Loss_D: 0.2567 (0.4020) Loss_G: 0.4321 (0.3148) D(x): 0.5415 D(G(z)): 0.4474 / 0.4213 Acc: 53.1250 (50.6250)\n",
      "(64,)\n",
      "[0/2][5/32] Loss_D: 0.1612 (0.3618) Loss_G: 0.5180 (0.3486) D(x): 0.5813 D(G(z)): 0.4180 / 0.3800 Acc: 42.1875 (49.2188)\n",
      "(64,)\n",
      "[0/2][6/32] Loss_D: 0.0558 (0.3181) Loss_G: 0.6338 (0.3894) D(x): 0.5955 D(G(z)): 0.3912 / 0.3389 Acc: 46.8750 (48.8839)\n",
      "(64,)\n",
      "[0/2][7/32] Loss_D: 0.0030 (0.2787) Loss_G: 0.5272 (0.4066) D(x): 0.5775 D(G(z)): 0.3705 / 0.3713 Acc: 64.0625 (50.7812)\n",
      "(64,)\n",
      "[0/2][8/32] Loss_D: -0.1122 (0.2353) Loss_G: 0.6276 (0.4311) D(x): 0.6597 D(G(z)): 0.3627 / 0.3438 Acc: 53.1250 (51.0417)\n",
      "(64,)\n",
      "[0/2][9/32] Loss_D: -0.2034 (0.1914) Loss_G: 0.6516 (0.4532) D(x): 0.6216 D(G(z)): 0.3390 / 0.3161 Acc: 59.3750 (51.8750)\n",
      "(64,)\n",
      "[0/2][10/32] Loss_D: -0.2009 (0.1558) Loss_G: 0.7300 (0.4783) D(x): 0.6546 D(G(z)): 0.3617 / 0.3167 Acc: 67.1875 (53.2670)\n",
      "(64,)\n",
      "[0/2][11/32] Loss_D: -0.1425 (0.1309) Loss_G: 0.9102 (0.5143) D(x): 0.6990 D(G(z)): 0.3590 / 0.2762 Acc: 53.1250 (53.2552)\n",
      "(64,)\n",
      "[0/2][12/32] Loss_D: 0.0546 (0.1250) Loss_G: 0.9144 (0.5451) D(x): 0.6635 D(G(z)): 0.3465 / 0.2950 Acc: 40.6250 (52.2837)\n",
      "(64,)\n",
      "[0/2][13/32] Loss_D: -0.2278 (0.0998) Loss_G: 0.8043 (0.5636) D(x): 0.6842 D(G(z)): 0.3234 / 0.2958 Acc: 51.5625 (52.2321)\n",
      "(64,)\n",
      "[0/2][14/32] Loss_D: -0.0134 (0.0923) Loss_G: 0.8507 (0.5828) D(x): 0.6490 D(G(z)): 0.3351 / 0.3057 Acc: 46.8750 (51.8750)\n",
      "(64,)\n",
      "[0/2][15/32] Loss_D: -0.0412 (0.0839) Loss_G: 0.6508 (0.5870) D(x): 0.6508 D(G(z)): 0.3882 / 0.3335 Acc: 53.1250 (51.9531)\n",
      "(64,)\n",
      "[0/2][16/32] Loss_D: 0.2111 (0.0914) Loss_G: 0.8970 (0.6052) D(x): 0.6418 D(G(z)): 0.4183 / 0.3125 Acc: 53.1250 (52.0221)\n",
      "(64,)\n",
      "[0/2][17/32] Loss_D: 0.0377 (0.0884) Loss_G: 0.9320 (0.6234) D(x): 0.6770 D(G(z)): 0.3890 / 0.3014 Acc: 54.6875 (52.1701)\n",
      "(64,)\n",
      "[0/2][18/32] Loss_D: -0.0185 (0.0828) Loss_G: 0.9786 (0.6421) D(x): 0.6097 D(G(z)): 0.3158 / 0.2602 Acc: 48.4375 (51.9737)\n",
      "(64,)\n",
      "[0/2][19/32] Loss_D: -0.1264 (0.0723) Loss_G: 0.9640 (0.6582) D(x): 0.6156 D(G(z)): 0.3115 / 0.2653 Acc: 65.6250 (52.6562)\n",
      "(64,)\n",
      "[0/2][20/32] Loss_D: -0.2325 (0.0578) Loss_G: 1.0118 (0.6750) D(x): 0.6600 D(G(z)): 0.3089 / 0.2421 Acc: 56.2500 (52.8274)\n",
      "(64,)\n",
      "[0/2][21/32] Loss_D: -0.0405 (0.0534) Loss_G: 0.9655 (0.6882) D(x): 0.6746 D(G(z)): 0.2974 / 0.2783 Acc: 48.4375 (52.6278)\n",
      "(64,)\n",
      "[0/2][22/32] Loss_D: -0.4253 (0.0325) Loss_G: 1.1127 (0.7067) D(x): 0.7532 D(G(z)): 0.3100 / 0.2480 Acc: 68.7500 (53.3288)\n",
      "(64,)\n",
      "[0/2][23/32] Loss_D: -0.3043 (0.0185) Loss_G: 1.3067 (0.7317) D(x): 0.7381 D(G(z)): 0.3093 / 0.1960 Acc: 51.5625 (53.2552)\n",
      "(64,)\n",
      "[0/2][24/32] Loss_D: -0.3284 (0.0046) Loss_G: 1.4138 (0.7590) D(x): 0.7242 D(G(z)): 0.2488 / 0.1882 Acc: 54.6875 (53.3125)\n",
      "(64,)\n",
      "[0/2][25/32] Loss_D: -0.5484 (-0.0166) Loss_G: 1.3806 (0.7829) D(x): 0.7871 D(G(z)): 0.2214 / 0.1986 Acc: 57.8125 (53.4856)\n",
      "(64,)\n",
      "[0/2][26/32] Loss_D: -0.5592 (-0.0367) Loss_G: 1.3276 (0.8031) D(x): 0.7993 D(G(z)): 0.2071 / 0.2059 Acc: 53.1250 (53.4722)\n",
      "(64,)\n",
      "[0/2][27/32] Loss_D: -0.3746 (-0.0488) Loss_G: 1.5136 (0.8284) D(x): 0.7873 D(G(z)): 0.2105 / 0.1822 Acc: 46.8750 (53.2366)\n",
      "(64,)\n",
      "[0/2][28/32] Loss_D: -0.6581 (-0.0698) Loss_G: 1.4522 (0.8499) D(x): 0.8429 D(G(z)): 0.2463 / 0.1740 Acc: 64.0625 (53.6099)\n",
      "(64,)\n",
      "[0/2][29/32] Loss_D: -0.6135 (-0.0879) Loss_G: 1.5057 (0.8718) D(x): 0.8609 D(G(z)): 0.2503 / 0.1677 Acc: 53.1250 (53.5938)\n",
      "(64,)\n",
      "[0/2][30/32] Loss_D: -0.4018 (-0.0981) Loss_G: 1.6170 (0.8958) D(x): 0.7630 D(G(z)): 0.2139 / 0.1687 Acc: 50.0000 (53.4778)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 16 is out of bounds for axis 0 with size 16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/xray_gan/acgan/main.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;31m#         eval_onehot[np.arange(opt.batchSize),0] = eval_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mclass_age\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_AGE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_onehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mclass_onehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclass_age\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mMAX_AGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mclass_gender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 16 is out of bounds for axis 0 with size 16"
     ]
    }
   ],
   "source": [
    "%run main.py --dataset=toytestdata --dataroot=/home/ubuntu/xray_gan/data/toytestdata/classes --cuda --niter=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batchSize=64, beta1=0.5, cuda=True, dataroot='../data', dataset='toytestdata', gpu_id=0, imageSize=32, lr=0.0002, manualSeed=None, ndf=64, netD='', netG='', ngf=64, ngpu=1, niter=2, num_classes=2, nz=110, outf='.', workers=2)\n",
      "Random Seed:  9110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision/transforms/transforms.py:211: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_netG_CIFAR10(\n",
      "  (fc1): Linear(in_features=110, out_features=384, bias=True)\n",
      "  (tconv2): Sequential(\n",
      "    (0): ConvTranspose2d(384, 192, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (tconv3): Sequential(\n",
      "    (0): ConvTranspose2d(192, 96, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (tconv4): Sequential(\n",
      "    (0): ConvTranspose2d(96, 48, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (tconv5): Sequential(\n",
      "    (0): ConvTranspose2d(48, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n",
      "_netD_CIFAR10(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (conv6): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc_dis): Linear(in_features=8192, out_features=1, bias=True)\n",
      "  (fc_aux): Linear(in_features=8192, out_features=2, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/xray_gan/acgan/network.py:276: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  classes = self.softmax(fc_aux)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n",
      "[0/2][0/1752] Loss_D: 0.4178 (0.4178) Loss_G: 0.3117 (0.3117) D(x): 0.5293 D(G(z)): 0.5209 / 0.4860 Acc: 56.2500 (56.2500)\n",
      "(64,)\n",
      "[0/2][1/1752] Loss_D: 0.1482 (0.2830) Loss_G: 0.3101 (0.3109) D(x): 0.5118 D(G(z)): 0.4919 / 0.4615 Acc: 95.3125 (75.7812)\n",
      "(64,)\n",
      "[0/2][2/1752] Loss_D: -0.1997 (0.1221) Loss_G: 0.3536 (0.3251) D(x): 0.5210 D(G(z)): 0.4356 / 0.4154 Acc: 100.0000 (83.8542)\n",
      "(64,)\n",
      "[0/2][3/1752] Loss_D: -0.2940 (0.0180) Loss_G: 0.3524 (0.3319) D(x): 0.5376 D(G(z)): 0.4388 / 0.4112 Acc: 100.0000 (87.8906)\n",
      "(64,)\n",
      "[0/2][4/1752] Loss_D: -0.2614 (-0.0378) Loss_G: 0.4120 (0.3479) D(x): 0.5661 D(G(z)): 0.4142 / 0.4353 Acc: 100.0000 (90.3125)\n",
      "(64,)\n",
      "[0/2][5/1752] Loss_D: -0.3085 (-0.0830) Loss_G: 0.4763 (0.3693) D(x): 0.5698 D(G(z)): 0.4214 / 0.3968 Acc: 100.0000 (91.9271)\n",
      "(64,)\n",
      "[0/2][6/1752] Loss_D: -0.5124 (-0.1443) Loss_G: 0.4625 (0.3827) D(x): 0.6276 D(G(z)): 0.3942 / 0.3868 Acc: 100.0000 (93.0804)\n",
      "(64,)\n",
      "[0/2][7/1752] Loss_D: -0.4650 (-0.1844) Loss_G: 0.7332 (0.4265) D(x): 0.6513 D(G(z)): 0.3621 / 0.3566 Acc: 100.0000 (93.9453)\n",
      "(64,)\n",
      "[0/2][8/1752] Loss_D: -0.4817 (-0.2174) Loss_G: 0.7457 (0.4619) D(x): 0.6146 D(G(z)): 0.3762 / 0.3090 Acc: 100.0000 (94.6181)\n",
      "(64,)\n",
      "[0/2][9/1752] Loss_D: -0.5832 (-0.2540) Loss_G: 0.6475 (0.4805) D(x): 0.6512 D(G(z)): 0.3655 / 0.3343 Acc: 100.0000 (95.1562)\n",
      "(64,)\n",
      "[0/2][10/1752] Loss_D: -0.6109 (-0.2864) Loss_G: 0.7618 (0.5061) D(x): 0.6726 D(G(z)): 0.3558 / 0.3098 Acc: 100.0000 (95.5966)\n",
      "(64,)\n",
      "[0/2][11/1752] Loss_D: -0.7154 (-0.3222) Loss_G: 0.5348 (0.5085) D(x): 0.6452 D(G(z)): 0.3249 / 0.3384 Acc: 100.0000 (95.9635)\n",
      "(64,)\n",
      "[0/2][12/1752] Loss_D: -0.6692 (-0.3489) Loss_G: 0.6684 (0.5208) D(x): 0.7194 D(G(z)): 0.4147 / 0.3178 Acc: 100.0000 (96.2740)\n",
      "(64,)\n",
      "[0/2][13/1752] Loss_D: -0.3862 (-0.3516) Loss_G: 0.9156 (0.5490) D(x): 0.6392 D(G(z)): 0.3913 / 0.3009 Acc: 100.0000 (96.5402)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/xray_gan/acgan/main.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0mavg_loss_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mniter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0;31m############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run main.py --dataset toytestdata --dataroot ../data --cuda --niter=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batchSize=64, beta1=0.5, cuda=True, dataroot='/home/ubuntu/xray_gan/data/toytestdata/classes', dataset='toytestdata', gpu_id=0, imageSize=32, lr=0.0002, manualSeed=None, ndf=64, netD='', netG='', ngf=64, ngpu=1, niter=2, num_classes=2, nz=110, outf='.', workers=2)\n",
      "Random Seed:  369\n",
      "_netG_CIFAR10(\n",
      "  (fc1): Linear(in_features=110, out_features=384, bias=True)\n",
      "  (tconv2): Sequential(\n",
      "    (0): ConvTranspose2d(384, 192, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (tconv3): Sequential(\n",
      "    (0): ConvTranspose2d(192, 96, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (tconv4): Sequential(\n",
      "    (0): ConvTranspose2d(96, 48, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (tconv5): Sequential(\n",
      "    (0): ConvTranspose2d(48, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n",
      "_netD_CIFAR10(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (conv6): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc_dis): Linear(in_features=8192, out_features=1, bias=True)\n",
      "  (fc_aux): Linear(in_features=8192, out_features=2, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision/transforms/transforms.py:211: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,) 64 64 (64,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/xray_gan/acgan/network.py:276: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  classes = self.softmax(fc_aux)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/2][0/32] Loss_D: 0.4449 (0.4449) Loss_G: 0.3186 (0.3186) D(x): 0.4569 D(G(z)): 0.4636 / 0.4709 Acc: 51.5625 (51.5625)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][1/32] Loss_D: 0.3819 (0.4134) Loss_G: 0.2927 (0.3057) D(x): 0.4831 D(G(z)): 0.4438 / 0.4616 Acc: 50.0000 (50.7812)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][2/32] Loss_D: 0.2548 (0.3606) Loss_G: 0.2541 (0.2885) D(x): 0.5712 D(G(z)): 0.4482 / 0.4848 Acc: 51.5625 (51.0417)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][3/32] Loss_D: 0.1326 (0.3036) Loss_G: 0.4085 (0.3185) D(x): 0.5978 D(G(z)): 0.4556 / 0.4133 Acc: 57.8125 (52.7344)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][4/32] Loss_D: 0.0795 (0.2588) Loss_G: 0.7149 (0.3978) D(x): 0.6063 D(G(z)): 0.4220 / 0.3216 Acc: 57.8125 (53.7500)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][5/32] Loss_D: -0.0281 (0.2110) Loss_G: 0.6809 (0.4449) D(x): 0.6052 D(G(z)): 0.3542 / 0.3405 Acc: 62.5000 (55.2083)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][6/32] Loss_D: -0.0321 (0.1762) Loss_G: 0.7047 (0.4821) D(x): 0.6435 D(G(z)): 0.3635 / 0.3384 Acc: 53.1250 (54.9107)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][7/32] Loss_D: -0.0133 (0.1525) Loss_G: 0.8851 (0.5324) D(x): 0.6495 D(G(z)): 0.3655 / 0.2897 Acc: 51.5625 (54.4922)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][8/32] Loss_D: -0.1405 (0.1200) Loss_G: 0.8112 (0.5634) D(x): 0.6569 D(G(z)): 0.3377 / 0.2915 Acc: 56.2500 (54.6875)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][9/32] Loss_D: -0.2856 (0.0794) Loss_G: 0.8738 (0.5945) D(x): 0.6670 D(G(z)): 0.2940 / 0.2826 Acc: 56.2500 (54.8438)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][10/32] Loss_D: -0.1656 (0.0571) Loss_G: 0.9820 (0.6297) D(x): 0.7117 D(G(z)): 0.3270 / 0.2730 Acc: 54.6875 (54.8295)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][11/32] Loss_D: -0.3547 (0.0228) Loss_G: 1.0824 (0.6674) D(x): 0.7668 D(G(z)): 0.2867 / 0.2404 Acc: 59.3750 (55.2083)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][12/32] Loss_D: -0.2868 (-0.0010) Loss_G: 0.9714 (0.6908) D(x): 0.7327 D(G(z)): 0.3109 / 0.2818 Acc: 59.3750 (55.5288)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][13/32] Loss_D: -0.2742 (-0.0205) Loss_G: 1.1622 (0.7245) D(x): 0.7390 D(G(z)): 0.3020 / 0.2266 Acc: 50.0000 (55.1339)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][14/32] Loss_D: -0.2017 (-0.0326) Loss_G: 0.9187 (0.7374) D(x): 0.6799 D(G(z)): 0.3029 / 0.2794 Acc: 50.0000 (54.7917)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][15/32] Loss_D: -0.2318 (-0.0450) Loss_G: 1.2557 (0.7698) D(x): 0.7831 D(G(z)): 0.3476 / 0.2192 Acc: 56.2500 (54.8828)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][16/32] Loss_D: -0.0635 (-0.0461) Loss_G: 1.2524 (0.7982) D(x): 0.6923 D(G(z)): 0.3458 / 0.2070 Acc: 43.7500 (54.2279)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][17/32] Loss_D: -0.1916 (-0.0542) Loss_G: 1.1334 (0.8168) D(x): 0.6305 D(G(z)): 0.2901 / 0.2152 Acc: 57.8125 (54.4271)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][18/32] Loss_D: -0.2925 (-0.0667) Loss_G: 1.2342 (0.8388) D(x): 0.6894 D(G(z)): 0.2753 / 0.2083 Acc: 60.9375 (54.7697)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][19/32] Loss_D: -0.1867 (-0.0727) Loss_G: 1.3825 (0.8660) D(x): 0.6868 D(G(z)): 0.2987 / 0.1808 Acc: 45.3125 (54.2969)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][20/32] Loss_D: -0.1087 (-0.0745) Loss_G: 1.3274 (0.8879) D(x): 0.6627 D(G(z)): 0.2668 / 0.2033 Acc: 50.0000 (54.0923)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][21/32] Loss_D: -0.4105 (-0.0897) Loss_G: 0.9508 (0.8908) D(x): 0.7614 D(G(z)): 0.2633 / 0.2581 Acc: 50.0000 (53.9062)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][22/32] Loss_D: -0.3039 (-0.0990) Loss_G: 1.4145 (0.9136) D(x): 0.7336 D(G(z)): 0.2736 / 0.1890 Acc: 53.1250 (53.8723)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][23/32] Loss_D: -0.5828 (-0.1192) Loss_G: 1.6888 (0.9459) D(x): 0.8063 D(G(z)): 0.2306 / 0.1363 Acc: 54.6875 (53.9062)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][24/32] Loss_D: -0.6296 (-0.1396) Loss_G: 1.6903 (0.9757) D(x): 0.7800 D(G(z)): 0.1834 / 0.1471 Acc: 57.8125 (54.0625)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][25/32] Loss_D: -0.4797 (-0.1527) Loss_G: 1.6152 (1.0002) D(x): 0.7746 D(G(z)): 0.1890 / 0.1628 Acc: 48.4375 (53.8462)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][26/32] Loss_D: -0.4974 (-0.1655) Loss_G: 1.7569 (1.0283) D(x): 0.8262 D(G(z)): 0.2316 / 0.1410 Acc: 51.5625 (53.7616)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][27/32] Loss_D: -0.1392 (-0.1645) Loss_G: 1.7060 (1.0525) D(x): 0.7518 D(G(z)): 0.1724 / 0.1634 Acc: 39.0625 (53.2366)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][28/32] Loss_D: -0.4297 (-0.1737) Loss_G: 1.7446 (1.0763) D(x): 0.8175 D(G(z)): 0.2263 / 0.1433 Acc: 46.8750 (53.0172)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][29/32] Loss_D: -0.6402 (-0.1892) Loss_G: 1.3808 (1.0865) D(x): 0.8317 D(G(z)): 0.1933 / 0.1866 Acc: 56.2500 (53.1250)\n",
      "(64,) 64 64 (64,)\n",
      "[0/2][30/32] Loss_D: -0.4924 (-0.1990) Loss_G: 1.7254 (1.1071) D(x): 0.8058 D(G(z)): 0.3225 / 0.1430 Acc: 67.1875 (53.5786)\n",
      "(64,) 16 64 (64,)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (16) must match the size of tensor b (64) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/xray_gan/acgan/main-debug.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0maux_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (16) must match the size of tensor b (64) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "%run main-debug.py --dataset=toytestdata --dataroot=/home/ubuntu/xray_gan/data/toytestdata/classes --cuda --niter=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
